{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07d34e7",
   "metadata": {},
   "source": [
    "# Predicting Student Exam Scores Using a Deep Learning model\n",
    "### (Not finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle as kg\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def preprocess_and_scaling(data):\n",
    "    # Preprocess and scale the data\n",
    "    # Placeholder for actual preprocessing and scaling logic\n",
    "    return data\n",
    "\n",
    "#Function for splitting data into training and validation sets\n",
    "def split_data(data, val_size=0.2):\n",
    "    train_data, val_data = train_test_split(data, test_size=val_size, random_state=42)\n",
    "    return train_data, val_data\n",
    "    \n",
    "\n",
    "#Dataloader:\n",
    "class StudentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        features = sample.drop('exam_score').values.astype(np.float32)\n",
    "        target = sample['exam_score'].astype(np.float32)\n",
    "        return features, target\n",
    "    \n",
    "def create_dataloader(data, batch_size=128, shuffle=True):\n",
    "    dataset = StudentDataset(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42df50",
   "metadata": {},
   "source": [
    "## Build model:\n",
    "\n",
    "I decided to use a simple architecture for the model, a MLP with 4 layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkModel(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetworkModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 32)\n",
    "        self.fc5 = torch.nn.Linear(32, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1eb090",
   "metadata": {},
   "source": [
    "### Define Function for training model using tqdm to keep track of progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc65e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, keep track of loss with tqdm progress bar.\n",
    "#Save Validation and train losses for each epoch.\n",
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloader_train.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in dataloader_val:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_epoch_loss = val_loss / len(dataloader_val.dataset)\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}\")\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91091f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
